{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CPH_final.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pryplotsky/C5.-Deep-Survival-Analysis-and-Time-Varying-Covariates/blob/main/CPH_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXIk0aH2daz5"
      },
      "source": [
        "### Install  packages and define global variables\n",
        "#Basic:\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "# 1. Read, save and load a data:\n",
        "import os\n",
        "import pickle\n",
        "# 2. Pre-process the data \n",
        "from sklearn import preprocessing\n",
        "# 3. Split the data into 3 sets\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "# 5. Create Cox time ( CPH for TVC) model\n",
        "!pip install lifelines\n",
        "import matplotlib.pyplot as plt\n",
        "from lifelines import CoxTimeVaryingFitter\n",
        "from lifelines import KaplanMeierFitter\n",
        "from lifelines.utils import concordance_index\n",
        "from sklearn.metrics import brier_score_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQVTfgtnneji"
      },
      "source": [
        "#Set global variables\n",
        "result_c_index=[]#extract c-index\n",
        "result_brier_score=[]#extract brier score\n",
        "pred_time=[21, 23, 40, 50]# set evaluation time\n",
        "k_event=['default_time', 'payoff_time']#set events\n",
        "var_list=['id', 'tte', 'times',\n",
        "       'balance_time', 'LTV_time', 'interest_rate_time', 'rate_time',\n",
        "       'hpi_time', 'gdp_time', 'uer_time','avg_balance_time', 'avg_interest_rate_time',\n",
        "       'avg_LTV_time', 'avg_rate_time', 'avg_hpi_time', 'avg_gdp_time',\n",
        "       'avg_uer_time','FICO_orig_time', 'REtype_CO_orig_time',\n",
        "       'REtype_PU_orig_time', 'REtype_SF_orig_time']"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7BxB1vqeYIB"
      },
      "source": [
        "**Main part of code**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4vI-6DjecCr"
      },
      "source": [
        "### Create class Preparation with 5 methods: __init__, readdf, save, load, cleaning and splitdata\n",
        "class Preparation:\n",
        "  def __init__(self):# Dont use any additional attributes    \n",
        "    self.df = None # Placeholders. Set varabels as none and then update a resut \n",
        "    self.X_train = None\n",
        "    self.X_test = None\n",
        "    self.y_train = None\n",
        "    self.y_test  = None\n",
        "    self.X_train = None\n",
        "    self.X_val = None\n",
        "    self.y_train = None\n",
        "    self.y_val = None\n",
        "    self.cols_standardize = ['id', 'tte', 'times','label',\n",
        "       'balance_time', 'LTV_time', 'interest_rate_time', 'rate_time',\n",
        "       'hpi_time', 'gdp_time', 'uer_time','avg_balance_time', 'avg_interest_rate_time',\n",
        "       'avg_LTV_time', 'avg_rate_time', 'avg_hpi_time', 'avg_gdp_time',\n",
        "       'avg_uer_time','FICO_orig_time', 'REtype_CO_orig_time',\n",
        "       'REtype_PU_orig_time', 'REtype_SF_orig_time', 'default_time', 'payoff_time']\n",
        "    #self.cols_standardize = ['rate_time','hpi_time', 'gdp_time']\n",
        "### Pre-processing:\n",
        "  # Read data\n",
        "  def readdf (self, sep=\",\", filename=\"dcr_cleaned.csv\", cwd = os.getcwd()): # Method whith 3 def attributes: sep - separator, getcwd - path to your working directory\n",
        "    file_name = cwd + \"/\" + filename # Get path of file\n",
        "    data = pd.read_csv(file_name, sep= sep) # Read csv\n",
        "    self.df = data # Save filtered dataset \n",
        "    return self.df # Print dataset\n",
        "  # Clean data\n",
        "  def cleaning (self, data,longformat=True,individual=\"id\", stop=\"times\", stopname=\"start\"): \n",
        "    if longformat:# Bring data into long format (necessary for using the lifeline package's Cox’s time varying proportional hazard model) \n",
        "        data[stopname] = data.groupby(individual)[stop].shift(1)\n",
        "        data[stopname] = data[stopname].fillna(0)\n",
        "        self.df = data # Save filtered dataset\n",
        "        return self.df # Print dataset\n",
        "### Saving and load objects as binary mode\n",
        "  def save (self, dataname, dataframe , cwd = os.getcwd()):# Saving and load objects as binary mode\n",
        "    with open( cwd + '/' + dataname + '.pkl','wb') as path_name: # save df, 'wb' specifies 'write'\n",
        "      pickle.dump(dataframe, path_name)  \n",
        "  def load (self, dataname, cwd = os.getcwd()):# Saving and load objects as binary mode\n",
        "    with open( cwd + '/' + dataname + '.pkl' ,'rb') as path_name:# load df, 'rb' specifies 'read'\n",
        "      dataframe = pickle.load(path_name)\n",
        "      return dataframe # Print dataset\n",
        "### Split the data into 3 sets: train(80%)  + dev (10%) + test(10%)  \n",
        "  def splitdata (self, Xvar, yvar, perc_test=0.2, perc_val=1/5,  shuffle=False):# Method needs 5 arguments: X set with independent vars, y - set w. dependent vars, perc_test=percentage for test set, perc_val=valuation set (=(1-perc_test)*perc_val) \n",
        "    self.X_train, self.X_test, self.y_train, self.y_test = sklearn.model_selection.train_test_split(Xvar, yvar, test_size=perc_test,random_state=1234,  shuffle=shuffle)# Split data not randomly to train 90% and test 10%\n",
        "    #self.X_train, self.X_val, self.y_train, self.y_val = sklearn.model_selection.train_test_split(self.X_train, self.y_train, test_size=perc_test,random_state=1234,  shuffle=shuffle) # Split train data not randomly to train 80% and valid 10%\n",
        "    print(len(self.X_train),  len(self.X_test)) # len - length "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yt6QrX8yno02"
      },
      "source": [
        "def brier_score(Prediction, Time_survival, Death, Time):#define a function to calculate a brier score\n",
        "    N = len(Prediction)\n",
        "    y_true = ((Time_survival <= Time) * Death).astype(float)\n",
        "    return np.mean((Prediction - y_true.values)**2)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgVII4anjaB8"
      },
      "source": [
        "**Cox Time model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOqQ1TZFVIve"
      },
      "source": [
        "for j in k_event:#loop over number evaluation times\n",
        "  var_list.append(j)\n",
        "  temp=Preparation()#define an obkect\n",
        "  newdf = temp.readdf()#read aur dataframe\n",
        "  df_to_use=temp.cleaning(temp.df)#clean our dataframe for CPH model\n",
        "  temp.splitdata(df_to_use.loc[:,df_to_use.columns != j], yvar=df_to_use[j])# split data into test and train set\n",
        "  X_train=temp.X_train#set train df with tvcs\n",
        "  y_train=temp.y_traint#set train df with dependent variable\n",
        "  df_full=X_train[['id', 'tte', 'times',\n",
        "       'balance_time', 'LTV_time', 'interest_rate_time', 'rate_time',\n",
        "       'hpi_time', 'gdp_time', 'uer_time','FICO_orig_time',  'start']]\n",
        "  df2=pd.concat([df_full,  y_train], axis=1)#merge df with dependent and independent variables\n",
        "  df3=df2.dropna()#drop missing values\n",
        "  for i in pred_time:#loop over number of events\n",
        "    X_test=temp.X_test#set test df with tvcs\n",
        "    y_test=temp.y_test#set test df with dependent variable\n",
        "    X_test=X_test[['id', 'tte', 'times',\n",
        "       'balance_time', 'LTV_time', 'interest_rate_time', 'rate_time',\n",
        "       'hpi_time', 'gdp_time', 'uer_time','FICO_orig_time',  'start']]\n",
        "    df2_test=pd.concat([X_test,  y_test], axis=1)#merge df with dependent and independent variables\n",
        "    df2_testb=df2_test.loc[df2_test['times']<=i]#set restriction for evaluation (equal prediction time plus evaluation time)\n",
        "    df3_test=df2_testb.dropna()#drop missing values\n",
        "    ctv = CoxTimeVaryingFitter(penalizer=0.1)#implements fitting Cox’s time-varying proportional hazard model \n",
        "    ctv.fit(df3, id_col=\"id\", event_col=j, start_col=\"start\", stop_col=\"times\", show_progress=True )\n",
        "    ctv.print_summary() #summary of the fitted model with different values of the parametric partial hazard and Partial AIC\n",
        "    ctv.plot() #visiualizaton of the covariates and how they are distributed\n",
        "    pred=ctv.baseline_cumulative_hazard_['baseline hazard'][i] * ctv.predict_partial_hazard(df3_test)#predicting the probabilities\n",
        "    res1=concordance_index(df3_test['times'], -pred, df3_test[j])# calculate a c-index\n",
        "    res2=brier_score(pred, df3_test['times']  ,df3_test[j] , i)# calculate a brier score\n",
        "    result_c_index.append(res1)\n",
        "    result_brier_score.append(res2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgwT92Sv0N1o"
      },
      "source": [
        "df_to_print=pd.DataFrame({'Event': k_event*4, 'Time': np.repeat(pred_time, 2 ), 'C-index': result_c_index,'Brier score': result_brier_score })# Prepare a table with results\n",
        "df_to_print.to_excel('df_res.xlsx')# Export table with results\n",
        "df_to_print"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}